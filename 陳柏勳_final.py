# -*- coding: utf-8 -*-
"""陳柏勳_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ZWLF2FtTT7reUHl9oEQO5FwXK0gnSP7

● age : 1 to 116

● ethnicity :0(White)、1(Black)、2(Asian)、
                  3(Indian)、4(Others)

● gender : 0(male)、1(female)
"""

!python --version
!pip freeze | grep torch

"""# Prepare Data"""

from google.colab import drive
drive.mount('/content/drive')

#!unzip -qq ./drive/My\ Drive/age_gender.zip

import csv
import os
import numpy as np
from PIL import Image
import torch
from sklearn.model_selection import train_test_split
from collections import OrderedDict
data = []
with open('/content/drive/MyDrive/data/age_gender.csv', newline='') as csvfile:
    mydata = csv.DictReader(csvfile)
    for row in mydata:
        data.append(row)
for i in range(len(data)):
  data[i]['pixels'] = np.array(data[i]['pixels'].split(), dtype="float32").reshape(48,48)
  data[i]['pixels'] = np.repeat(data[i]['pixels'][..., np.newaxis], 3, -1).swapaxes(0,2)
train_data, val_data = train_test_split(data, random_state=7, train_size=0.8)
val_data, test_data = train_test_split(val_data, random_state=0, train_size=0.6)
print(train_data[2]['pixels'])
print(len(train_data))
print(len(val_data))
print(len(test_data))

import pandas as pd
df=pd.read_csv('/content/drive/MyDrive/data/age_gender.csv')
df.head()

X=np.zeros(shape=(23705,2304))

for i in range(len(df.pixels)):
    df.pixels[i]=np.array(df.pixels[i].split(),dtype='float32')
    X[i]=df.pixels[i]

X_reshaped=X.reshape(-1,48,48,1)
index=np.random.randint(0,23704,25)

import matplotlib.pyplot as plt
plt.figure(figsize=(16,16))

for i in range(len(index)):
    plt.subplot(5,5,(i%25)+1)
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(X_reshaped[index[i]].reshape(48,48))
    plt.xlabel(
        "Age:"+str(df['age'].iloc[index[i]])+
        " Ethnicity:"+str(df['ethnicity'].iloc[index[i]])+
        " Gender:"+str(df['gender'].iloc[index[i]])
    )
    
plt.show()

"""## Loading the dataset

### Custom dataset

繼承自定義資料集的框架 `torch.utils.data.Dataset`，主要實現 `__getitem__()` 和 `__len__()` 這兩個方法。

常使用來做到設定資料位址、設定讀取方式、子資料集的標籤和轉換條件...等。

See [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for more details
"""

import csv
import os
import numpy as np
from PIL import Image
import torch

class FashionData(torch.utils.data.Dataset):
    def __init__(self, mydata, mode='train'):
        
        self.data_list = []
        self.age_label = []
        self.ethnicity_label = []
        self.gender_label = []
        
        for row in mydata:
            self.data_list.append(row['pixels'])
            if mode != 'test':
                self.age_label.append(row['age'])
                self.ethnicity_label.append(row['ethnicity'])
                self.gender_label.append(row['gender'])

    def __getitem__(self, index):

        data = self.data_list[index]
        data = torch.Tensor(data)
        age_label = torch.tensor(int(self.age_label[index]))
        ethnicity_label = torch.tensor(int(self.ethnicity_label[index]))
        gender_label = torch.tensor(int(self.gender_label[index]))
        
        return data, age_label, ethnicity_label, gender_label

    def __len__(self):
        return len(self.data_list)

dataset_train = FashionData(train_data, mode='train')
dataset_val = FashionData(val_data, mode='val')
dataset_test = FashionData(test_data, mode='test')

print("The first image's shape in dataset_train :", dataset_train.__getitem__(0)[0].size())
print("There are", dataset_train.__len__(), "images in dataset_train.")
print("There are", dataset_val.__len__(), "images in dataset_val.")
print("There are", dataset_test.__len__(), "images in dataset_test.")

"""### `DataLoader`

`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:
+ `shuffle` : set to `True` to have the data reshuffled at every epoch
+ `batch_size` : how many samples per batch to load

See [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details
"""

from torch.utils.data import DataLoader

train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True)
val_loader = DataLoader(dataset_val, batch_size=128, shuffle=False)
test_loader = DataLoader(dataset_test, batch_size=128, shuffle=False)

print(dataset_train.__getitem__(1)[0].size())
print(dataset_train[1][0])
print(dataset_train.__getitem__(1)[1].size())
print(dataset_train[1][1])
print(dataset_train.__getitem__(1)[2].size())
print(dataset_train[1][2])
print(dataset_train.__getitem__(1)[3].size())
print(dataset_train[1][3])

"""# Implement CNN using PyTorch

### Define a Convolutional Neural Network

Try to design and train a deep convolutional network from scratch to predict the class label of a flower image. 

You can refer to last assignment about image_classifier, and try to go deep and use more method for better model.

import torch.nn as nn 
import torch.nn.functional as F

class CNN_Model(nn.Module): 
	def __init__(self): 
		super().__init__()
		########################################################################
		#     TODO: use nn.xxx method to generate a CNN model part             #
		########################################################################
		# Convolution 1 , input_shape=(3,48,48)
		self.cnn1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1) #output_shape=(12,48,48)
		self.Batch1 = nn.BatchNorm2d(12)
		self.relu1 = nn.ReLU()
		self.maxpool1 = nn.MaxPool2d(kernel_size=2) #output_shape=(12,24,24)
		# Convolution 2 , input_shape=(12,24,24)
		self.cnn2 = nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, stride=1, padding=1) #output_shape=(16,24,24)
		self.Batch2 = nn.BatchNorm2d(16)
		self.relu2 = nn.ReLU()
		self.maxpool2 = nn.MaxPool2d(kernel_size=2) #output_shape=(16,12,12)
		self.avgpool = nn.AdaptiveAvgPool2d(1)
    # Fully connected 1 ,#input_shape=(16*12*12)
		self.fc1 = nn.Linear(16 , 117)
		self.fc2 = nn.Linear(16 , 5)
		self.fc3 = nn.Linear(16 , 2)
		########################################################################
		#                           End of your code                           #
		########################################################################

	def forward(self, x): 
		if not isinstance(x, torch.Tensor):
			x = torch.Tensor(x)
		########################################################################
		#     TODO: forward your model and get output                          #
		########################################################################
		# Convolution 1
		x = self.cnn1(x)
		x = self.Batch1(x)
		x = self.relu1(x)
		x = self.maxpool1(x)
    # Convolution 2  
		x = self.cnn2(x)
		x = self.Batch2(x)
		x = self.relu2(x)
		x = self.maxpool2(x)
		x = self.avgpool(x)
		x = x.view(x.size(0),-1)
		out1 = self.fc1(x)
		out2 = self.fc2(x)
		out3 = self.fc3(x)
		########################################################################
		#                           End of your code                           #
		########################################################################
		return out1, out2, out3
"""

##　self attention
import torch
import torch.nn as nn
import torch.nn.functional as F

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")


class AugmentedConv(nn.Module):
  def __init__(self, in_channels, out_channels, kernel_size, dk, dv, Nh, relative):
    super(AugmentedConv, self).__init__()
    self.in_channels = in_channels
    self.out_channels = out_channels
    self.kernel_size = kernel_size
    self.dk = dk
    self.dv = dv
    self.Nh = Nh
    self.relative = relative
    self.conv_out = nn.Conv2d(self.in_channels, self.out_channels - self.dv, self.kernel_size, padding=1)
    self.qkv_conv = nn.Conv2d(self.in_channels, 2 * self.dk + self.dv, kernel_size=1)
    self.attn_out = nn.Conv2d(self.dv, self.dv, 1)
  def forward(self, x):
    # Input x
    # (batch_size, channels, height, width)
    batch, _, height, width = x.size()
    
    # conv_out
    # (batch_size, out_channels, height, width)
    conv_out = self.conv_out(x)

    # flat_q, flat_k, flat_v
    # (batch_size, Nh, height * width, dvh or dkh)
    # dvh = dv / Nh, dkh = dk / Nh
    # q, k, v
    # (batch_size, Nh, height, width, dv or dk)
    flat_q, flat_k, flat_v, q, k, v = self.compute_flat_qkv(x, self.dk, self.dv, self.Nh)
    logits = torch.matmul(flat_q.transpose(2, 3), flat_k)

    if self.relative:
      h_rel_logits, w_rel_logits = self.relative_logits(q)
      logits += h_rel_logits
      logits += w_rel_logits
    weights = F.softmax(logits, dim=-1)

    # attn_out
    # (batch, Nh, height * width, dvh)
    attn_out = torch.matmul(weights, flat_v.transpose(2, 3))
    attn_out = torch.reshape(attn_out, (batch, self.Nh, self.dv // self.Nh, height, width))
    # combine_heads_2d
    # (batch, out_channels, height, width)
    attn_out = self.combine_heads_2d(attn_out)
    attn_out = self.attn_out(attn_out)
    return torch.cat((conv_out, attn_out), dim=1)

  def compute_flat_qkv(self, x, dk, dv, Nh):
    N, _, H, W = x.size()
    qkv = self.qkv_conv(x)
    q, k, v = torch.split(qkv, [dk, dk, dv], dim=1)
    q = self.split_heads_2d(q, Nh)
    k = self.split_heads_2d(k, Nh)
    v = self.split_heads_2d(v, Nh)

    dkh = dk // Nh
    q *= dkh ** -0.5
    flat_q = torch.reshape(q, (N, Nh, dk // Nh, H * W))
    flat_k = torch.reshape(k, (N, Nh, dk // Nh, H * W))
    flat_v = torch.reshape(v, (N, Nh, dv // Nh, H * W))
    return flat_q, flat_k, flat_v, q, k, v

  def split_heads_2d(self, x, Nh):
    batch, channels, height, width = x.size()
    ret_shape = (batch, Nh, channels // Nh, height, width)
    split = torch.reshape(x, ret_shape)
    return split

  def combine_heads_2d(self, x):
    batch, Nh, dv, H, W = x.size()
    ret_shape = (batch, Nh * dv, H, W)
    return torch.reshape(x, ret_shape)

  def relative_logits(self, q):
    B, Nh, dk, H, W = q.size()
    q = torch.transpose(q, 2, 4).transpose(2, 3)

    key_rel_w = nn.Parameter(torch.randn((2 * W - 1, dk), requires_grad=True)).to(device)
    rel_logits_w = self.relative_logits_1d(q, key_rel_w, H, W, Nh, "w")

    key_rel_h = nn.Parameter(torch.randn((2 * H - 1, dk), requires_grad=True)).to(device)
    rel_logits_h = self.relative_logits_1d(torch.transpose(q, 2, 3), key_rel_h, W, H, Nh, "h")

    return rel_logits_h, rel_logits_w

  def relative_logits_1d(self, q, rel_k, H, W, Nh, case):
    rel_logits = torch.einsum('bhxyd,md->bhxym', q, rel_k)
    rel_logits = torch.reshape(rel_logits, (-1, Nh * H, W, 2 * W - 1))
    rel_logits = self.rel_to_abs(rel_logits)

    rel_logits = torch.reshape(rel_logits, (-1, Nh, H, W, W))
    rel_logits = torch.unsqueeze(rel_logits, dim=3)
    rel_logits = rel_logits.repeat((1, 1, 1, H, 1, 1))

    if case == "w":
      rel_logits = torch.transpose(rel_logits, 3, 4)
    elif case == "h":
      rel_logits = torch.transpose(rel_logits, 2, 4).transpose(4, 5).transpose(3, 5)
    rel_logits = torch.reshape(rel_logits, (-1, Nh, H * W, H * W))
    return rel_logits

  def rel_to_abs(self, x):
    B, Nh, L, _ = x.size()

    col_pad = torch.zeros((B, Nh, L, 1)).to(device)
    x = torch.cat((x, col_pad), dim=3)

    flat_x = torch.reshape(x, (B, Nh, L * 2 * L))
    flat_pad = torch.zeros((B, Nh, L - 1)).to(device)
    flat_x_padded = torch.cat((flat_x, flat_pad), dim=2)

    final_x = torch.reshape(flat_x_padded, (B, Nh, L + 1, 2 * L - 1))
    final_x = final_x[:, :, :L, L - 1:]
    return final_x

import torch.nn as nn 
import torch.nn.functional as F
import torchvision.models as models

class PT_Model(nn.Module): 
  def __init__(self): 
    super().__init__()

    self.layer1 = nn.Sequential(
        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
        nn.LeakyReLU(),
		nn.BatchNorm2d(32))
    self.augmented_conv1 = AugmentedConv(in_channels=32, out_channels=64, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer2= nn.Sequential(
        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
        nn.LeakyReLU(),
		nn.BatchNorm2d(128))
    self.augmented_conv2 = AugmentedConv(in_channels=128, out_channels=256, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer3 = nn.Sequential(
        nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),
        nn.LeakyReLU(),
		nn.BatchNorm2d(128))
    self.augmented_conv3 = AugmentedConv(in_channels=128, out_channels=64, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer4 = nn.Sequential(
        nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),
        nn.LeakyReLU(),
		nn.BatchNorm2d(3))
    self.cnn_model = models.resnet101(pretrained=True)
    self.cnn_model = nn.Sequential(*(list(self.cnn_model.children())[:-2]))
    self.augmented_conv5 = AugmentedConv(in_channels=2048, out_channels=512, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer5 = nn.Sequential(
        nn.LeakyReLU(),
		nn.BatchNorm2d(512))
    self.augmented_conv6 = AugmentedConv(in_channels=512, out_channels=256, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer6 = nn.Sequential(
        nn.LeakyReLU(),
		nn.BatchNorm2d(256))
    self.augmented_conv7 = AugmentedConv(in_channels=256, out_channels=256, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer7 = nn.Sequential(
        nn.LeakyReLU(),
		nn.BatchNorm2d(256))
    self.augmented_conv8 = AugmentedConv(in_channels=256, out_channels=256, kernel_size=3, dk=40, dv=4, Nh=4, relative=True)
    self.layer8 = nn.Sequential(
        nn.LeakyReLU(),
		nn.BatchNorm2d(256))
    self.avepool = nn.AdaptiveAvgPool2d(output_size=(1, 1))
    self.fc1 = nn.Linear(256,117)
    self.fc2 = nn.Linear(256,5)
    self.fc3 = nn.Linear(256,2)
  def forward(self, x): 
    if not isinstance(x, torch.Tensor):
      x = torch.Tensor(x)
    x = self.cnn_model(x)
    x = self.augmented_conv5(x)
    x = self.layer5(x)
    x = self.augmented_conv6(x)
    x = self.layer6(x)
    x = self.augmented_conv7(x)
    x = self.layer7(x)
    x = self.augmented_conv8(x)
    x = self.layer8(x)
    x = self.avepool(x)
    x = x.view(x.size(0),-1)
    out1 = self.fc1(x)
    out2 = self.fc2(x)
    out3 = self.fc3(x)
    return out1, out2, out3

"""
model = CNN_Model()
model = model.cuda()
print(model)
"""

import torch.nn as nn 
import torch.nn.functional as F
import torchvision.models as models

class PT_Model(nn.Module): 
	def __init__(self): 
		super().__init__()
		########################################################################
		#     TODO: use nn.xxx method to generate a CNN model part             #
		########################################################################
		self.cnn_model = models.resnet18(pretrained=True)
		self.cnn_model = nn.Sequential(*(list(self.cnn_model.children())[:-1]))
		ct = 0
		for child in self.cnn_model.children():
			ct += 1
			if ct < 7:
				for param in child.parameters():
					param.requires_grad = False
		self.fc1 = nn.Linear(512,117)
		self.fc2 = nn.Linear(512,5)
		self.fc3 = nn.Linear(512,2)
		########################################################################
		#                           End of your code                           #
		########################################################################

	def forward(self, x): 
		if not isinstance(x, torch.Tensor):
			x = torch.Tensor(x)
		########################################################################
		#     TODO: forward your model and get output                          #
		########################################################################
		x = self.cnn_model(x)
		x = x.view(x.size(0),-1)
		out1 = self.fc1(x)
		out2 = self.fc2(x)
		out3 = self.fc3(x)
		########################################################################
		#                           End of your code                           #
		########################################################################
		return out1, out2, out3

model = PT_Model()
model = model.cuda()
#print(model)

print(model)

"""We have made our model!  
Next, PyTorch also provide many utility function(loss, optmizer...etc).  
You can define them in one-line.

### Define loss and optimizer
"""

import torch.nn as nn
import torch.optim as optim
################################################################################
# TODO: Define loss and optmizer functions                                     #
# Try any loss or optimizer function and learning rate to get better result    #
# hint: torch.nn and torch.optim                                               #
################################################################################
criterion1, criterion2, criterion3 = nn.CrossEntropyLoss(), nn.CrossEntropyLoss(), nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
#optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)
################################################################################
#                               End of your code                               #
################################################################################
criterion1, criterion2, criterion3 = criterion1.cuda(), criterion2.cuda(), criterion3.cuda()

"""### Train the model

#### Train function
Let's define train function.  
It will iterate input data 1 epoch and update model with optmizer.  
Finally, calculate mean loss and total accuracy.

Hint: [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html#torch-max)
"""

def train(input_data, model, criterion1, criterion2, criterion3, optimizer):
    
    model.train()
    loss1_list = []
    loss2_list = []
    loss3_list = []
    total_count = 0
    acc1_count = 0
    acc2_count = 0
    acc3_count = 0
    for i, data in enumerate(input_data, 0):
        images, age_label, ethnicity_label, gender_label = data[0].cuda(), data[1].cuda(), data[2].cuda(), data[3].cuda()
        
        optimizer.zero_grad()
        outputs1, outputs2, outputs3 = model(images)
        loss1 = criterion1(outputs1, age_label)
        loss2 = criterion2(outputs2, ethnicity_label)
        loss3 = criterion3(outputs3, gender_label)
        loss = 5*loss1 + 2*loss2 + 1*loss3
        loss.backward()
        optimizer.step()
        
        _, predicted1 = torch.max(outputs1.data, 1)
        _, predicted2 = torch.max(outputs2.data, 1)
        _, predicted3 = torch.max(outputs3.data, 1)
        total_count += len(age_label)
        for i in range(-5,6):
          acc1_count += (predicted1 == age_label + i).sum().item()
        acc2_count += (predicted2 == ethnicity_label).sum().item()
        acc3_count += (predicted3 == gender_label).sum().item()
        loss1_list.append(loss1)
        loss2_list.append(loss2)
        loss3_list.append(loss3)
        

    # Compute this epoch accuracy and loss
    acc1 = acc1_count / total_count
    acc2 = acc2_count / total_count
    acc3 = acc3_count / total_count
    loss1 = sum(loss1_list) / len(loss1_list)
    loss2 = sum(loss2_list) / len(loss2_list)
    loss3 = sum(loss3_list) / len(loss3_list)
    return acc1, acc2, acc3, loss1, loss2, loss3

"""#### Validate function
Next part is validate function.  
It works as training function without optmizer and weight-updating part.
"""

def val(input_data, model, criterion1, criterion2, criterion3):
    model.eval()
    
    loss1_list = []
    loss2_list = []
    loss3_list = []
    total_count = 0
    acc1_count = 0
    acc2_count = 0
    acc3_count = 0
    with torch.no_grad():
        for data in input_data:
            images, age_label, ethnicity_label, gender_label = data[0].cuda(), data[1].cuda(), data[2].cuda(), data[3].cuda()

            
            outputs1, outputs2, outputs3 = model(images)
            loss1 = criterion1(outputs1, age_label)
            loss2 = criterion2(outputs2, ethnicity_label)
            loss3 = criterion3(outputs3, gender_label)
            loss = 5*loss1 + 2*loss2 + 1*loss3
            _, predicted1 = torch.max(outputs1.data, 1)
            _, predicted2 = torch.max(outputs2.data, 1)
            _, predicted3 = torch.max(outputs3.data, 1)
            total_count += len(age_label)
            for i in range(-5,6):
              acc1_count += (predicted1 == age_label + i).sum().item()
            acc2_count += (predicted2 == ethnicity_label).sum().item()
            acc3_count += (predicted3 == gender_label).sum().item()
            loss1_list.append(loss1)
            loss2_list.append(loss2)
            loss3_list.append(loss3)
            
    acc1 = acc1_count / total_count
    acc2 = acc2_count / total_count
    acc3 = acc3_count / total_count
    loss1 = sum(loss1_list) / len(loss1_list)
    loss2 = sum(loss2_list) / len(loss2_list)
    loss3 = sum(loss3_list) / len(loss3_list)
    return acc1, acc2, acc3, loss1, loss2, loss3

"""#### Training in a loop
Call train and test function in a loop.  
Take a break and wait.
"""

################################################################################
# You can adjust those hyper parameters to loop for max_epochs times           #
################################################################################
max_epochs = 3
log_interval = 1 # print acc and loss in per log_interval time
################################################################################
#                               End of your code                               #
################################################################################
train_acc1_list = []
train_loss1_list = []
train_acc2_list = []
train_loss2_list = []
train_acc3_list = []
train_loss3_list = []
val_acc1_list = []
val_loss1_list = []
val_acc2_list = []
val_loss2_list = []
val_acc3_list = []
val_loss3_list = []

for epoch in range(1, max_epochs + 1):
    train_acc1, train_acc2, train_acc3, train_loss1, train_loss2, train_loss3 = train(train_loader, model, criterion1, criterion2, criterion3, optimizer)
    val_acc1, val_acc2, val_acc3, val_loss1, val_loss2, val_loss3 = val(val_loader, model, criterion1, criterion2, criterion3)

    train_acc1_list.append(train_acc1)
    train_loss1_list.append(train_loss1)
    train_acc2_list.append(train_acc2)
    train_loss2_list.append(train_loss2)
    train_acc3_list.append(train_acc3)
    train_loss3_list.append(train_loss3)
    val_acc1_list.append(val_acc1)
    val_loss1_list.append(val_loss1)
    val_acc2_list.append(val_acc2)
    val_loss2_list.append(val_loss2)
    val_acc3_list.append(val_acc3)
    val_loss3_list.append(val_loss3)
    if epoch % log_interval == 0:
        print('=' * 20, 'Epoch', epoch, '=' * 20)
        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc1, train_loss1))
        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc1, val_loss1))
        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc2, train_loss2))
        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc2, val_loss2))
        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc3, train_loss3))
        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc3, val_loss3))

"""#### Visualize accuracy and loss"""

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.plot(range(len(train_loss1_list)), train_loss1_list)
plt.plot(range(len(val_loss1_list)), val_loss1_list, c='r')
plt.legend(['train', 'val'])
plt.title('Loss1')
plt.show()
plt.figure(figsize=(12, 4))
plt.plot(range(len(train_acc1_list)), train_acc1_list)
plt.plot(range(len(val_acc1_list)), val_acc1_list, c='r')
plt.legend(['train', 'val'])
plt.title('Acc1')
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.plot(range(len(train_loss2_list)), train_loss2_list)
plt.plot(range(len(val_loss2_list)), val_loss2_list, c='r')
plt.legend(['train', 'val'])
plt.title('Loss2')
plt.show()
plt.figure(figsize=(12, 4))
plt.plot(range(len(train_acc2_list)), train_acc2_list)
plt.plot(range(len(val_acc2_list)), val_acc2_list, c='r')
plt.legend(['train', 'val'])
plt.title('Acc2')
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.plot(range(len(train_loss3_list)), train_loss3_list)
plt.plot(range(len(val_loss3_list)), val_loss3_list, c='r')
plt.legend(['train', 'val'])
plt.title('Loss3')
plt.show()
plt.figure(figsize=(12, 4))
plt.plot(range(len(train_acc3_list)), train_acc3_list)
plt.plot(range(len(val_acc3_list)), val_acc3_list, c='r')
plt.legend(['train', 'val'])
plt.title('Acc3')
plt.show()

"""### Predict Result

預測`test`並將結果上傳至Kaggle。[**連結**](https://www.kaggle.com/t/a16786b7da97419f9ba90b495dab08aa)

執行完畢此區的程式碼後，會將`test`預測完的結果存下來。

上傳流程
1. 點選左側選單最下方的資料夾圖示
2. 右鍵「result.csv」
3. 點選「Download」
4. 至連結網頁點選「Submit Predictions」
5. 將剛剛下載的檔案上傳
6. 系統會計算並公布其中70%資料的正確率

def predict(input_data, model):
    model.eval()
    output_list1 = []
    output_list2 = []
    data_list = []
    with open('./deep_fashion/test.csv', newline='') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            data_list.append(row['file_path'])
    with torch.no_grad():
        for data in input_data:
            images = data.cuda()
            outputs1, outputs2 = model(images)
            _, predicted1 = torch.max(outputs1.data, 1)
            predicted2 = (outputs2.data > 0.5)*1
            output_list1.extend(predicted1.to('cpu').numpy().tolist())
            output_list2.extend(predicted2.to('cpu').numpy().tolist())
    return output_list1, output_list2, data_list

output_csv1, output_csv2, data_list = predict(test_loader, model)
idx = 0
with open('result1.csv', 'w', newline='') as csvFile:
    writer = csv.DictWriter(csvFile, fieldnames=['file_path', 'category_label'])
    writer.writeheader()
    for result1 in output_csv1:
        idx+=1
        writer.writerow({'file_path':data_list[idx-1], 'category_label':result1})
idx = 0
with open('result2.csv', 'w', newline='') as csvFile:
    writer = csv.DictWriter(csvFile, fieldnames=['file_path', 'attribute_label'])
    writer.writeheader()
    for result2 in output_csv2:
        att = str()
        for ind in range(15):
            if result2[ind]==1:
                att += (str(ind) + str(' '))
        att = att[:len(att)-1]
        writer.writerow({'file_path':data_list[idx], 'attribute_label':att})
        idx+=1
"""

# Keep trying and write report

持續調整模型、訓練方法、損失函數、優化器等，來訓練出更好的模型，並記錄使用不同參數得出的效果，以利後續 Report 的撰寫。

大家加油！
"""

import cv2
import numpy as np
from torchvision import transforms
import io
import requests
from PIL import Image
from torchvision import models, transforms
from torch.autograd import Variable
import matplotlib.pyplot as plt
imsize = 48
loader = transforms.Compose([transforms.Resize(imsize),transforms.ToTensor()])
def image_loader(image_name):
    image = Image.open(image_name)
    image = 255*loader(image).float()
    image = Variable(image, requires_grad=True)
    return image.cuda()
img = image_loader('/content/drive/MyDrive/深度學習/Colab_python/final/final_picture/x1.jpg')
img = torch.reshape(img,(1,3,48,48))
cls = model(img)
m=list(cls[0].cpu()[0].detach().numpy().argsort()[-5:][::-1])
a = torch.tensor(round(sum(m)/len(m)))
b = cls[1].argmax()
c = cls[2].argmax()
a = a.cpu()
b = b.cpu()
c = c.cpu()
model(img)

image = cv2.imread('/content/drive/MyDrive/深度學習/Colab_python/final/final_picture/x1.jpg',0)
plt.figure(figsize=(4,4))
plt.grid(False)
plt.xticks([])
plt.yticks([])
plt.imshow(image, cmap="gray")
plt.xlabel("Age:"+str(a.numpy())+ " Ethnicity:"+str(b.numpy())+" Gender:"+str(c.numpy()))



"""# my work"""

img = cv2.imread('/content/drive/MyDrive/final_picture/p1.jpg',0)
plt.imshow(img, cmap="gray")
img = np.repeat(img[..., np.newaxis], 3, -1).swapaxes(0,2)
img = torch.Tensor(img)
img.shape

img = torch.reshape(img, (1, 3, 48, 48))
img







from keras.models import Sequential
model = Sequential()

model